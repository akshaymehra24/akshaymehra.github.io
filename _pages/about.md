---
permalink: /
title: ""
excerpt: "PhD student at Tulane University"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


<p style="text-align: justify;">
  
I am a fourth year PhD student at Tulane University, working with <a href ="http://www.cs.tulane.edu/~jhamm3/"> Prof. Jihun Hamm</a>. My current research is related to understanding the robustness of machine learning under distribution shifts. I also work on developing methods for solving large-scale bilevel optimization problems that appear in popular machine learning such as hyperparameter optimization, few-shot learning, importance learning and training-data poisoning.
<br><br>
Previously, I have completed my Masters in Computer Science from The Ohio State University under the guidance of <a href ="http://www.cs.tulane.edu/~jhamm3/"> Prof. Jihun Hamm</a> and <a href="http://misha.belkin-wang.org/">Prof. Mikhail Belkin</a> where I worked on active learning and semi-supervised learning problems.

</p>

Research Interest
======
<p style="text-align: justify;">
To deepen the understanding of robustness of machine learning models to different types of distribution shifts such as shifts induced by corrupted data, shifts induced by adversarial attacks, etc..
</p>

Publications
======
* “[On Certifying and Improving Generalization to Unseen Domains](https://arxiv.org/abs/2206.12364)”. 
  <br> [Code](https://github.com/akshaymehra24/CertifiableDG)
  <br> <b>Akshay Mehra</b>, Bhavya Kailkhura, Pin-Yu Chen and Jihun Hamm. 
* “[Certified Adversarial Defenses Meet Out-of-Distribution Corruptions: Benchmarking Robustness and Simple Baselines](https://arxiv.org/abs/2112.00659)”. 
  <br> Jiachen Sun, <b>Akshay Mehra</b>, Bhavya Kailkhura, Pin-Yu Chen, Dan Hendrycks, Jihun Hamm and Z. Morley Mao.
* “[Understanding the Limits of Unsupervised Domain Adaptation via Data Poisoning](https://papers.nips.cc/paper/2021/file/90cc440b1b8caa520c562ac4e4bbcb51-Paper.pdf)”. 
  <br> [Code](https://github.com/akshaymehra24/LimitsOfUDA), [Poster](http://akshaymehra24.github.io/files/Neurips_2021_poster.pdf)
  <br> <b>Akshay Mehra</b>, Bhavya Kailkhura, Pin-Yu Chen and Jihun Hamm. 
  <br> <i>Neural Information Processing Systems (NeurIPS) 2021.</i>
* “[How Robust are Randomized Smoothing based Defenses to Data Poisoning?](https://openaccess.thecvf.com/content/CVPR2021/html/Mehra_How_Robust_Are_Randomized_Smoothing_Based_Defenses_to_Data_Poisoning_CVPR_2021_paper.html)”. 
  <br> [Code](https://github.com/akshaymehra24/poisoning_certified_defenses), [Poster](http://akshaymehra24.github.io/files/cvpr21_poster.pdf)
  <br> <b>Akshay Mehra</b>, Bhavya Kailkhura, Pin-Yu Chen and Jihun Hamm. 
  <br> <i>Computer Vision and Pattern Recognition (CVPR) 2021. </i>
* “[Penalty Method for Inversion-Free Deep Bilevel Optimization](https://arxiv.org/abs/1911.03432)”. 
  <br> [Code](https://github.com/jihunhamm/bilevel-penalty), [Poster](http://akshaymehra24.github.io/files/acml21_poster.pdf)
  <br> <b>Akshay Mehra</b>, Jihun Hamm. 
  <br> <i>Asian Conference on Machine Learning (ACML) 2021.</i>
* “[Fast Interactive Image Retrieval using large-scale unlabeled data](https://arxiv.org/abs/1802.04204)”.
  <br> <b>Akshay Mehra</b>, Jihun Hamm and Mikhail Belkin. 
* “[Machine vs Machine: Minimax-Optimal Defense Against Adversarial Examples](https://arxiv.org/abs/1711.04368)”.
  <br> Jihun Hamm and <b>Akshay Mehra</b>. 
